{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ ê°€ì´ë“œ í˜¼ê³µ\n",
    "\n",
    "### 2019.03.05 ~ 2019.03.28 êµì¬ 1,2ì¥\n",
    "\n",
    "ì½”ë¡œë‚˜19 ì‚¬íƒœë¡œ 1,2ì¥ì€ í˜¼ì ê³µë¶€í•´ì•¼ í•˜ëŠ”ë°, ì–‘ì´ ë§ì•„ì„œ ë†ë•¡ì´ ë¶€ë¦¬ì§€ ë§ê³  ì—´ì‹¬íˆ í•˜ì^*^\n",
    "\n",
    "01. íŒŒì´ì¬ ê¸°ë°˜ì˜ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ìƒíƒœê³„ ì´í•´ \n",
    "02. ì‚¬ì´í‚·ëŸ°ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹\n",
    "\n",
    "Let's get startedâš½ï¸!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-13-Fri\n",
    "\n",
    "ì§„ë„: 01. ì‚¬ì´í‚·ëŸ° ì†Œê°œì™€ íŠ¹ì§• ~ (87ìª½ ~) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ì¥ ì‚¬ì´í‚·ëŸ°ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ \n",
    "\n",
    "### 01. ì‚¬ì´í‚·ëŸ° ì†Œê°œì™€ íŠ¹ì§•\n",
    "\n",
    "- ì‚¬ì´í‚·ëŸ°(scikit-learn)ì€ íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤‘ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- íŒŒì´ì¬ ê¸°ë°˜ì˜ ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ê°€ì¥ ì‰½ê³  íš¨ìœ¨ì ì¸ ê°œë°œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì œê³µ\n",
    "- Anacondaë¥¼ ì„¤ì¹˜í•˜ë©´ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ì´í‚·ëŸ°ê¹Œì§€ ì„¤ì¹˜ê°€ ì™„ë£Œ\n",
    "\n",
    "### 02. ì²« ë²ˆì§¸ ë¨¸ì‹ ëŸ¬ë‹ ë§Œë“¤ì–´ ë³´ê¸° - ë¶“ê½ƒ í’ˆì¢… ì˜ˆì¸¡í•˜ê¸°\n",
    "\n",
    "- ì‚¬ì´í‚·ëŸ°ì„ í†µí•´ ì²«ë²ˆì§¸ë¡œ ë§Œë“¤ì–´ë³¼ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ **ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ë¡œ ë¶“ê½ƒì˜ í’ˆì¢…ì„ ë¶„ë¥˜(Classification)**í•˜ëŠ” ê²ƒ!\n",
    "- ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ëŠ” ê½ƒìì˜ ê¸¸ì´ì™€ ë„ˆë¹„, ê½ƒë°›ì¹¨ì˜ ê¸¸ì´ì™€ ë„ˆë¹„ í”¼ì²˜(feature)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ê½ƒì˜ í’ˆì¢…ì„ ì˜ˆì¸¡**í•˜ê¸° ìœ„í•œ ê²ƒ\n",
    "- ML ì•Œê³ ë¦¬ì¦˜ì€ **ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬(Decision Tree) ì•Œê³ ë¦¬ì¦˜**ìœ¼ë¡œ, ì´ë¥¼ êµ¬í˜„í•œ **DecisionTreeClassifier**ë¥¼ ì ìš©\n",
    "\n",
    "#### ë¶„ë¥˜(Classification) \n",
    "- ë¶„ë¥˜ëŠ” ëŒ€í‘œì ì¸ **ì§€ë„í•™ìŠµ(Supervised Learning)** ë°©ë²•ì˜ í•˜ë‚˜ \n",
    "- ì§€ë„í•™ìŠµì€ í•™ìŠµì„ ìœ„í•œ ë‹¤ì–‘í•œ **í”¼ì²˜(feature, íŠ¹ì§•ë“¤)**ì™€ ë¶„ë¥˜ ê²°ì •ê°’ì¸ **ë ˆì´ë¸”(Label, ë¶„ë¥˜ë°©ì‹)** ë°ì´í„°ë¡œ ëª¨ë¸ì„ í•™ìŠµí•œ ë’¤, ë³„ë„ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë¯¸ì§€ì˜ ë ˆì´ë¸”ì„ ì˜ˆì¸¡ \n",
    "- ì¦‰, ì§€ë„í•™ìŠµì€ **ëª…í™•í•œ ì •ë‹µì´ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¨¼ì € í•™ìŠµ - train set**í•œ ë’¤, **ë¯¸ì§€ì˜ ì •ë‹µì„ ì˜ˆì¸¡ - test set**í•˜ëŠ” ë°©ì‹ \n",
    "\n",
    "#### ë² ì´ìŠ¤ ë¼ì¸ êµ¬ì¶•\n",
    "\n",
    "##### ë°ì´í„° ë¡œë”©\n",
    "- **sklearn.datasets**: ì‚¬ì´í‚·ëŸ°ì—ì„œ ìì²´ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë“ˆì˜ ëª¨ì„\n",
    "- **sklearn.tree**: íŠ¸ë¦¬ ê¸°ë°˜ ML ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ í´ë˜ìŠ¤ì˜ ëª¨ì„\n",
    "- **sklearn.model_selection**: í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°, ì˜ˆì¸¡ ë°ì´í„°ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ê±°ë‚˜ ìµœì ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ í‰ê°€í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ëª¨ë“ˆì˜ ëª¨ì„\n",
    "- **í•˜ì´í¼ íŒŒë¼ë¯¸í„°**: ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ë³„ë¡œ ìµœì ì˜ í•™ìŠµì„ ìœ„í•´ ì§ì ‘ ì…ë ¥í•˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤ì„ í†µì¹˜, í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ íŠœë‹í•  ìˆ˜ ìˆìŒ. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ ìƒì„±\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split  # ë°ì´í„° ì„¸íŠ¸ë¥¼ í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris targetê°’: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris targetëª…: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ ë¡œë”© \n",
    "iris = load_iris()\n",
    "\n",
    "# iris.dataëŠ” iris ë°ì´í„° ì„¸íŠ¸ì—ì„œ í”¼ì²˜(feature)ë§Œìœ¼ë¡œ ëœ ë°ì´í„°ë¥¼ numpyë¡œ ê°€ì§€ê³  ìˆìŒ. \n",
    "iris_data = iris.data\n",
    "\n",
    "# iris.targetì€ ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë ˆì´ë¸”(ê²°ì • ê°’) ë°ì´í„°ë¥¼ numpyë¡œ ê°€ì§€ê³  ìˆìŒ. \n",
    "iris_label = iris.target\n",
    "print('iris targetê°’:', iris_label)\n",
    "print('iris targetëª…:', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìì„¸íˆ ë³´ê¸° ìœ„í•´ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### í•™ìŠµìš© ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° í™•ë³´í•˜ê¸° \n",
    "\n",
    "- í•™ìŠµ ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ê°€ì§€ëŠ”ì§€ í‰ê°€í•˜ë ¤ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ê°€ í•„ìš”\n",
    "- ì‚¬ì´í‚·ëŸ°ì€ **train_test_split()**ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‰½ê²Œ ë¶„í• í•  ìˆ˜ ìˆìŒ. \n",
    "- **test_size íŒŒë¼ë¯¸í„°**ë¥¼ ì´ìš©í•˜ë©´ ì…ë ¥ ê°’ì˜ ë¹„ìœ¨ë¡œ ì‰½ê²Œ ë¶„í• . ì˜ˆë¥¼ ë“¤ì–´ test_size=0.2ë¼ë©´, ì „ì²´ ë°ì´í„° ì¤‘ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ 20%, í•™ìŠµ ë°ì´í„°ê°€ 80%ë¡œ ë°ì´í„°ë¥¼ ë¶„í• í•¨\n",
    "- **random_state=n**: í˜¸ì¶œí•  ë•Œë§ˆë‹¤ 'ê°™ì€' í•™ìŠµ/í…ŒìŠ¤íŠ¸ ìš© ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•˜ê¸°ìœ„í•´ ì£¼ì–´ì§€ëŠ” ë‚œìˆ˜ ë°œìƒ ê°’. ìˆ«ì ìì²´ëŠ” ì–´ë–¤ ê°’ì„ ì§€ì •í•´ë„ ìƒê´€ì—†ìŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trainì€ í•™ìŠµìš© í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸ \n",
    "# X_testëŠ” í…ŒìŠ¤íŠ¸ìš© í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸ \n",
    "# y_trainì€ í•™ìŠµìš© ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ \n",
    "# y_testëŠ” í…ŒìŠ¤íŠ¸ìš© ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,\n",
    "                                                   test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬ë¥¼ ì´ìš©í•´ í•™ìŠµí•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier ê°ì²´ ìƒì„± \n",
    "dt_clf = DecisionTreeClassifier(random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=11, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•™ìŠµ ìˆ˜í–‰ \n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬ë¥¼ ì´ìš©í•´ ì˜ˆì¸¡í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµì´ ì™„ë£Œëœ DecisionTreeClassifier ê°ì²´ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ \n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€í•˜ê¸°\n",
    "\n",
    "- ML ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ë ¤ í•¨. \n",
    "- ì •í™•ë„ëŠ” ì˜ˆì¸¡ ê²°ê³¼ê°€ ì‹¤ì œ ë ˆì´ë¸” ê°’ê³¼ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ë§ëŠ”ì§€ë¥¼ í‰ê°€í•˜ëŠ” ì§€í‘œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì •í™•ë„: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('ì˜ˆì¸¡ ì •í™•ë„: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì •ë¦¬ \n",
    "1. ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬: ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ë¦¬ \n",
    "2. ëª¨ë¸ í•™ìŠµ: í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ML ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚´ \n",
    "3. ì˜ˆì¸¡ ìˆ˜í–‰: í•™ìŠµëœ ML ëª¨ë¸ì„ ì´ìš©í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¶„ë¥˜(ì¦‰, ë¶“ê½ƒ ì¢…ë¥˜)ë¥¼ ì˜ˆì¸¡ \n",
    "4. í‰ê°€: ì´ë ‡ê²Œ ì˜ˆì¸¡ëœ ê²°ê´ê°’ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì‹¤ì œ ê²°ê´ê°’ì„ ë¹„êµí•´ ML ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-16-Mon\n",
    "\n",
    "ì§„ë„: 03. ì‚¬ì´í‚·ëŸ°ì˜ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ ìµíˆê¸° ~ (93ìª½ ~) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. ì‚¬ì´í‚·ëŸ°ì˜ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ ìµíˆê¸° \n",
    "\n",
    "#### Estimator ì´í•´ ë° fit(), predict() ë©”ì„œë“œ\n",
    "\n",
    "ì‚¬ì´í‚·ëŸ°ì€ **ì§€ë„í•™ìŠµ**ì˜ ê²½ìš° ML ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œ **fit( )**ì„, í•™ìŠµëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ìœ„í•´ **predict( )**ë¥¼ ì œê³µí•¨. ì§€ë„í•™ìŠµì˜ ì£¼ìš” ë‘ ì¶•ì¸ ë¶„ë¥˜ì™€ íšŒê·€ì˜ ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ ì‚¬ì´í‚·ëŸ°ì€ fit()ê³¼ predict()ë§Œ ê°€ì§€ê³  ê°„ë‹¨í•˜ê²Œ í•™ìŠµê³¼ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°˜í™˜í•¨. \n",
    "\n",
    "- ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ í´ë˜ìŠ¤ **Classifier(ex. ì–‘ì´ë‚˜ ìˆ˜, ìì „ê±° ëŒ€ì—¬ëŸ‰, ìƒí’ˆíŒë§¤ëŸ‰, ê°ìˆ˜ëŸ‰ ë“±)**, íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ **Regressor(ex. ë¶„ë¥˜ text ë°ì´í„° ê¸ë¶€ì •, ëŒ“ê¸€ ì£¼ì œ íŒŒì•…\n",
    "- Classifierì™€ Regressorë¥¼ í•©ì³ì„œ **Estimator í´ë˜ìŠ¤**ë¼ í•¨. ì¦‰, ì§€ë„í•™ìŠµì˜ ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ í´ë˜ìŠ¤ë¥¼ í†µì¹­í•˜ì—¬ Estimatorë¼ ë¶€ë¦„.\n",
    "\n",
    "ì‚¬ì´í‚·ëŸ°ì—ì„œ **ë¹„ì§€ë„í•™ìŠµ**ì¸ ì°¨ì› ì¶•ì†Œ, í´ëŸ¬ìŠ¤í„°ë§, í”¼ì²˜ ì¶”ì¶œ ë“±ì„ êµ¬í˜„í•œ í´ë˜ìŠ¤ ëŒ€ë¶€ë¶„ **fit()ê³¼ transform()**ì„ ì ìš©í•¨. ì—¬ê¸°ì„œ fit()ì€ ì…ë ¥ ë°ì´í„°ì˜ í˜•íƒœì— ë§ì¶° ë°ì´í„°ë¥¼ ë³€í™˜í•˜ê¸°ìœ„í•œ ì‚¬ì „ êµ¬ì¡°ë¥¼ ë§ì¶”ëŠ” ì‘ì—…. ì…ë ¥ ë°ì´í„°ì˜ ì°¨ì› ë³€í™˜, í´ëŸ¬ìŠ¤í„°ë§, í”¼ì²˜ ì¶”ì¶œ ë“±ì˜ ì‹¤ì œ ì‘ì—…ì€ transform()ìœ¼ë¡œ ìˆ˜í–‰. \n",
    "\n",
    "#### ì‚¬ì´í‚·ëŸ°ì˜ ì£¼ìš” ëª¨ë“ˆ\n",
    "\n",
    "ì¼ë°˜ì ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ì£¼ìš” í”„ë¡œì„¸ìŠ¤ëŠ” **í”¼ì²˜ ì²˜ë¦¬(feature processing, í”¼ì²˜ì˜ ê°€ê³µ, ë³€ê²½, ì¶”ì¶œì„ ìˆ˜í–‰), ML ì•Œê³ ë¦¬ì¦˜ í•™ìŠµ/ì˜ˆì¸¡ ìˆ˜í–‰, ëª¨ë¸ í‰ê°€ ë‹¨ê³„**ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰ ğŸ‘‰ ì´ë ‡ê²Œ í•˜ë©´ì„œ ì„±ëŠ¥ì„ ë†’ì—¬ì•¼ì§€! \n",
    "\n",
    "#### ë‚´ì¥ëœ ì˜ˆì œ ë°ì´í„° ì„¸íŠ¸ \n",
    "\n",
    "ë¶„ë¥˜ë‚˜ íšŒê·€ ì—°ìŠµìš© ì˜ˆì œ ë°ì´í„°ì™€ ë¶„ë¥˜ë‚˜ í´ëŸ¬ìŠ¤íŠ¸ë§ì„ ìœ„í•´ í‘œë³¸ ë°ì´í„°ë¡œ ìƒì„±ë  ìˆ˜ ìˆëŠ” ë°ì´í„° ì„¸íŠ¸ë¡œ ë‚˜ëˆ ì ¸ìˆìŒ. \n",
    "\n",
    "ë¶„ë¥˜ë‚˜ íšŒê·€ë¥¼ ìœ„í•œ ì—°ìŠµìš© ì˜ˆì œ ë°ì´í„° í‚¤(key)\n",
    "- data: í”¼ì²˜ì˜ ë°ì´í„° ì„¸íŠ¸ \n",
    "- target: ë¶„ë¥˜ ì‹œ ë ˆì´ë¸” ê°’, íšŒê·€ì¼ ë•ŒëŠ” ìˆ«ì ê²°ê´ê°’ ë°ì´í„° ì„¸íŠ¸ \n",
    "- target_names: ê°œë³„ ë ˆì´ë¸”ì˜ ì´ë¦„\n",
    "- feature_names: í”¼ì²˜ì˜ ì´ë¦„ \n",
    "- DESCR: ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì„¤ëª…ê³¼ ê° í”¼ì²˜ì˜ ì„¤ëª… "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris   \n",
    "\n",
    "iris_data = load_iris()   #load_iris()ë¥¼ ë³€ìˆ˜ì— ë‹´ì•„ì¤˜ì•¼ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì§€!\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bunch** í´ë˜ìŠ¤ëŠ” íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ ìë£Œí˜•ê³¼ ìœ ì‚¬í•¨. ê·¸ë˜ì„œ keyê°’ì´ ìˆìœ¼ë‹ˆ keyê°’ì„ í™•ì¸í•´ë³´ë©´, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names ì˜ type: <class 'list'>\n",
      " feature_names ì˜ shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_namesì˜ type: <class 'numpy.ndarray'>\n",
      " target_namesì˜ shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " dataì˜ type: <class 'numpy.ndarray'>\n",
      " dataì˜ shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " targetì˜ type: <class 'numpy.ndarray'>\n",
      " targetì˜ shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('\\n feature_names ì˜ type:', type(iris_data.feature_names))\n",
    "print(' feature_names ì˜ shape:', len(iris_data.feature_names))  #len()ì´ ì—¬ê¸°ì„œëŠ” ë¦¬ìŠ¤íŠ¸ ì•ˆì— ëª‡ê°œ? \n",
    "print(iris_data.feature_names)\n",
    "\n",
    "\n",
    "print('\\n target_namesì˜ type:', type(iris_data.target_names))\n",
    "print(' target_namesì˜ shape:', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n dataì˜ type:', type(iris_data.data)) #dataëŠ” í”¼ì²˜ì˜ ë°ì´í„°ê°’ \n",
    "print(' dataì˜ shape:', iris_data.data.shape)  #ndarrayë¼ shapeì„ ì“¸ ìˆ˜ ìˆìŒ. \n",
    "print(iris_data['data'])\n",
    "\n",
    "print('\\n targetì˜ type:', type(iris_data.target))\n",
    "print(' targetì˜ shape:', iris_data.target.shape)\n",
    "print(iris_data.target)                       #iris_data['target'] ì´ë ‡ê²Œ ë³´ê² ë‹¤ í•˜ëŠ” ê²ƒ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-18-Wed\n",
    "\n",
    "ì§„ë„: 03. ì‚¬ì´í‚·ëŸ°ì˜ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ ìµíˆê¸° ~ (100ìª½ ~) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Model Selection ëª¨ë“ˆ ì†Œê°œ \n",
    "\n",
    "ì‚¬ì´í‚·ëŸ°ì˜ **model_selection ëª¨ë“ˆ**\n",
    "1. **í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„ë¦¬**\n",
    "2. **êµì°¨ ê²€ì¦ ë¶„í•  ë° í‰ê°€**\n",
    "3. **Estimatorì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ê¸°ìœ„í•œ ë‹¤ì–‘í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì œê³µ**\n",
    "\n",
    "#### í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬ - train_test_split()\n",
    "\n",
    "ë¨¼ì € í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì´ìš©í•˜ì§€ ì•Šê³  í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë¡œë§Œ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•˜ë©´ ë¬´ì—‡ì´ ë¬¸ì œì¼ê¹Œ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì •í™•ë„: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target \n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ \n",
    "pred = dt_clf.predict(train_data)\n",
    "print('ì˜ˆì¸¡ ì •í™•ë„:', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¹ì—°íˆ ì˜ˆì¸¡ì´ 100%ê°€ ë˜ì§€. ê·¸ë˜ì„œ **train_text_split()**ì„ ì´ìš©í•´ ì›ë³¸ ë°ì´í„° ì„¸íŠ¸ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„ë¦¬í•´ì•¼ í•¨.\n",
    "\n",
    "- sklearn.model_selection(í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸, ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸, ì˜µì…˜) \n",
    "- test_size: ì „ì²´ ë°ì´í„°ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ í¬ê¸°ë¥¼ ì–¼ë§ˆë¡œ ìƒ˜í”Œë§í•  ê²ƒì¸ê°€ \n",
    "- random_state: í˜¸ì¶œí•  ë•Œë§ˆë‹¤ ë™ì¼í•œ í•™ìŠµ/í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•˜ê¸°ìœ„í•´ ì£¼ì–´ì§€ëŠ” ë‚œìˆ˜ ê°’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì •í™•ë„: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split   # ì—¬ê¸° ëª¨ë“ˆì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²ƒ! \n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                   test_size=0.3, random_state=121)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('ì˜ˆì¸¡ ì •í™•ë„: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì˜ ì–‘ì„ ì¼ì •ìˆ˜ì¤€ ì´ìƒìœ¼ë¡œ ë³´ì¥í•˜ëŠ” ê²ƒë„ ì¤‘ìš”, ê·¸ëŸ¬ë‚˜ í•™ìŠµëœ ëª¨ë¸ì— ëŒ€í•´ ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í‰ê°€í•´ë³´ëŠ” ê²ƒë„ ë§¤ìš° ì¤‘ìš”. (ë¶“ê½ƒ ë°ì´í„°ëŠ” 150ê°œì˜ ë°ì´í„°ë¼ 30% í•´ë´¤ì í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” 45ê°œ, ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ íŒë‹¨í•˜ê¸°ì—ëŠ” ì ì ˆí•˜ì§€ ì•ŠìŒ.) \n",
    "\n",
    "#### êµì°¨ ê²€ì¦\n",
    "\n",
    "í•™ìŠµ ë°ì´í„°ì™€ ë°ìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ë‚˜ëˆ„ëŠ”ë° ì´ ë°©ë²• ì—­ì‹œ **ê³¼ì í•©(Overfitting)**ì— ì·¨ì•½í•˜ë‹¤ëŠ” ì•½ì ì´ ìˆìŒ. ê³¼ì í•©ì€ ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì—ë§Œ ê³¼ë„í•˜ê²Œ ìµœì í™”ë˜ì–´, ì‹¤ì œ ì˜ˆì¸¡ì„ ë‹¤ë¥¸ ë°ì´í„°ë¡œ ìˆ˜í–‰í•  ê²½ìš°ì—ëŠ” ì˜ˆì¸¡ ì„±ëŠ¥ì´ ê³¼ë„í•˜ê²Œ ë–¨ì–´ì§€ëŠ” ê²ƒì„ ë§í•¨. ì´ëŸ¬í•œ ë¬¸ì œì ì„ ê°œì„ í•˜ê¸°ìœ„í•´ **êµì°¨ ê²€ì¦**ì„ ì´ìš©í•´ ë” ë‹¤ì–‘í•œ í•™ìŠµê³¼ í‰ê°€ë¥¼ ìˆ˜í–‰í•¨. \n",
    "\n",
    "**êµì°¨ê²€ì¦**ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´ ë³¸ê³ ì‚¬ë¥¼ ì¹˜ë¥´ê¸° ì „ì— ëª¨ì˜ê³ ì‚¬ë¥¼ ì—¬ëŸ¬ ë²ˆ ë³´ëŠ” ê²ƒ. êµì°¨ ê²€ì¦ì€ ë°ì´í„° í¸ì¤‘ì„ ë§‰ê¸° ìœ„í•´ ë³„ë„ì˜ ì—¬ëŸ¬ ì„¸íŠ¸ë¡œ êµ¬ì„±ëœ í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ì™€ ê²€ì¦ ë°ì´í„° ì„¸íŠ¸ì—ì„œ í•™ìŠµê³¼ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„. ëŒ€ë¶€ë¶„ì˜ ML ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ëŠ” êµì°¨ ê²€ì¦ ê¸°ë°˜ìœ¼ë¡œ 1ì°¨ í‰ê°€ë¥¼ í•œ í›„ì— ìµœì¢…ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ì— ì ìš©í•´ í‰ê°€í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì„.\n",
    "\n",
    "- ë¨¼ì € í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¡œ ë¶„í• \n",
    "- ê·¸ í›„ í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë¥¼ í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ì™€ **ê²€ì¦ ë°ì´í„° ì„¸íŠ¸**ë¡œ ë¶„í•  \n",
    "\n",
    "##### K í´ë“œ êµì°¨ ê²€ì¦ \n",
    "\n",
    "K í´ë“œ êµì°¨ ê²€ì¦ì€ ê°€ì¥ ë³´í¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” êµì°¨ ê²€ì¦ ê¸°ë²•. Kê°œì˜ ë°ì´í„° í´ë“œ ì„¸íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ Kë²ˆë§Œí¼ ê° í´íŠ¸ ì„¸íŠ¸ì— í•™ìŠµê³¼ ê²€ì¦ í‰ê°€ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰. \n",
    "- [5 í´ë“œ êµì°¨ ê²€ì¦ ê³¼ì •](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F9916854E5AC0B61D220CD3)\n",
    "- ì‚¬ì´í‚·ëŸ°ì—ì„œëŠ” K í´ë“œ êµì°¨ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ **KFoldì™€ StratifiedKFOLD** í´ë˜ìŠ¤ë¥¼ ì œê³µí•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ í¬ê¸°: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data \n",
    "label = iris.target \n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "# 5ê°œì˜ í´ë“œ ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•˜ëŠ” KFold ê°ì²´ì™€ í´ë“œ ì„¸íŠ¸ë³„ ì •í™•ë„ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ê°ì²´ ìƒì„±.\n",
    "kfold = KFold(n_splits=5)    #5ë²ˆ ê²€ì¦í•˜ê² ë‹¤ ì„¤ì •!\n",
    "cv_accuracy = []\n",
    "print('ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ í¬ê¸°:', features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒì„±ëœ KFold ê°ì²´ì˜ split()ì„ í˜¸ì¶œí•´ ì „ì²´ ë¶“ê½ƒ ë°ì´í„°ë¥¼ 5ê°œì˜ í´ë“œ ë°ì´í„° ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•¨. KFold ê°ì²´ëŠ” split()ì„ í˜¸ì¶œí•˜ë©´ í•™ìŠµìš©/ê²€ì¦ìš© ë°ì´í„°ë¥¼ ë¶„í• í•  ìˆ˜ ìˆëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•¨. ì‹¤ì œë¡œ í•™ìŠµìš©/ê²€ì¦ìš© ë°ì´í„° ì¶”ì¶œì€ **ë°˜í™˜ëœ ì¸ë±ìŠ¤**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œë°œ ì½”ë“œì—ì„œ ì§ì ‘ ìˆ˜í–‰í•´ì•¼ í•¨. ì¦‰, split()ì€ í•™ìŠµìš©ê³¼ ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¸ë±ìŠ¤ë¡œ splití•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 êµì°¨ ê²€ì¦ ì •í™•ë„ :1.0, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ë¦¬: 30\n",
      "#1 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.9667, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ë¦¬: 30\n",
      "#2 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.8667, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ë¦¬: 30\n",
      "#3 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.9333, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ë¦¬: 30\n",
      "#4 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.7333, í•™ìŠµ ë°ì´í„° í¬ê¸°: 120, ê²€ì¦ ë°ì´í„° í¬ë¦¬: 30\n",
      "#5 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## í‰ê·  ê²€ì¦ ì •í™•ë„: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold ê°ì²´ì˜ split()ë¥¼ í˜¸ì¶œí•˜ë©´ í´ë“œ ë³„ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ì˜ ë¡œìš° ì¸ë±ìŠ¤ë¥¼ arrayë¡œ ë°˜í™˜ \n",
    "for train_index, test_index in kfold.split(features):\n",
    "    #kfold.split()ìœ¼ë¡œ ë°˜í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•´ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ \n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #í•™ìŠµ ë° ì˜ˆì¸¡ \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    # ë°˜ë³µ ì‹œë§ˆë‹¤ ì •í™•ë„ ì¸¡ì • \n",
    "    accuracy = np.round(accuracy_score(y_test, pred),4)   #np.round(a,n): aë¥¼ nìë¦¬ìˆ˜ì—ì„œ ë°˜ì˜¬ë¦¼\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ :{1}, í•™ìŠµ ë°ì´í„° í¬ê¸°: {2}, ê²€ì¦ ë°ì´í„° í¬ë¦¬: {3}'\n",
    "         .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤: {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# ê°œë³„ interactionë³„ ì •í™•ë„ë¥¼ í•©í•˜ì—¬ í‰ê·  ì •í™•ë„ ê³„ì‚° \n",
    "print('\\n## í‰ê·  ê²€ì¦ ì •í™•ë„:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5ë²ˆ êµì°¨ ê²€ì¦ ê²°ê³¼ í‰ê·  ê²€ì¦ ì •í™•ë„ëŠ” 0.9, êµì°¨ ê²€ì¦ ì‹œë§ˆë‹¤ ê²€ì¦ ì„¸íŠ¸ì˜ ì¸ë±ìŠ¤ê°€ ë‹¬ë¼ì§. \n",
    "\n",
    "#### Stratified K í´ë“œ \n",
    "\n",
    "**ë¶ˆê· í˜•í•œ ë¶„í¬ë„ë¥¼ ê°€ì§„ ë ˆì´ë¸” ë°ì´í„° ì§‘í•©ì„ ìœ„í•œ K í´ë“œ ë°©ì‹**ì„. íŠ¹ì • ë ˆì´ë¸” ê°’ì´ íŠ¹ì´í•˜ê²Œ ë§ê±°ë‚˜ ë§¤ìš° ì ì–´ì„œ ê°’ì˜ ë¶„í¬ê°€ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹  ë•Œ. ì˜ˆë¥¼ ë“¤ì–´ ëŒ€ì¶œ ì‚¬ê¸° ë°ì´í„° ì˜ˆì¸¡. ëŒ€ì¶œ ì‚¬ê¸°ê°€ ì•½ 1000ê±´ ìˆë‹¤ê³  í•˜ë©´ ì „ì²´ì˜ 0.0001%ì˜ ì•„ì£¼ ì‘ì€ í™•ë¥ ë¡œ ëŒ€ì¶œ ì‚¬ê¸° ë ˆì´ë¸”ì´ ì¡´ì¬í•¨. K í´ë“œë¡œ ëœë˜í•˜ê²Œ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì¸ë±ìŠ¤ë¥¼ ê³ ë¥´ë”ë¼ë„ ë ˆì´ë¸” ê°’ì¸ 0ê³¼ 1ì˜ ë¹„ìœ¨ì„ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ì‰½ê²Œ ë°œìƒí•¨. ëŒ€ì¶œ ì‚¬ê¸° ë ˆì´ë¸”ì´ 1ì¸ ë ˆì½”ë“œëŠ” ë¹„ë¡ ê±´ìˆ˜ëŠ” ì‘ì§€ë§Œ ì•Œê³ ë¦¬ì¦˜ì´ ëŒ€ì¶œ ì‚¬ê¸°ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ì¤‘ìš”í•œ í”¼ì²˜ ê°’ì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ë§¤ìš° ì¤‘ìš”í•œ ë°ì´í„° ì„¸íŠ¸ì„. ë”°ë¼ì„œ ì›ë³¸ ë°ì´í„°ì™€ ìœ ì‚¬í•œ ëŒ€ì¶œ ì‚¬ê¸° ë ˆì´ë¸” ê°’ì˜ ë¶„í¬ë¥¼ í•™ìŠµ/ë°ì´í„° ì„¸íŠ¸ì—ë„ ìœ ì§€í•˜ëŠ”ê²Œ ë§¤ìš° ì¤‘ìš”í•¨.**Stratified K í´ë“œëŠ” ì›ë³¸ ë°ì´í„°ì˜ ë ˆì´ë¸” ë¶„í¬ë¥¼ ë¨¼ì € ê³ ë ¤í•œ ë’¤ ì´ ë¶„í¬ì™€ ë™ì¼í•˜ê²Œ í•™ìŠµê³¼ ê²€ì¦ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„ë°°í•¨.**\n",
    "\n",
    "K í´ë“œê°€ ì–´ë–¤ ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ ë³´ê³ , ì´ë¥¼ ì‚¬ì´í‚·ëŸ°ì˜ StratifiedKFold í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ ê°œì„ í•´ ë³¼ ê²ƒ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: lable, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['lable'] = iris.target \n",
    "iris_df['lable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## êµì°¨ ê²€ì¦: 1\n",
      "í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    50\n",
      "1    50\n",
      "Name: lable, dtype: int64\n",
      "ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 0    50\n",
      "Name: lable, dtype: int64\n",
      "## êµì°¨ ê²€ì¦: 2\n",
      "í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    50\n",
      "0    50\n",
      "Name: lable, dtype: int64\n",
      "ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 1    50\n",
      "Name: lable, dtype: int64\n",
      "## êµì°¨ ê²€ì¦: 3\n",
      "í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 1    50\n",
      "0    50\n",
      "Name: lable, dtype: int64\n",
      "ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    50\n",
      "Name: lable, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "# kfold.split(X)ëŠ” í´ë“œ ì„¸íŠ¸ë¥¼ 3ë²ˆ ë°˜ë³µí•  ë•Œë§ˆë‹¤ ë‹¬ë¼ì§€ëŠ” í•™ìŠµ/í…ŒìŠ¤íŠ¸ ìš© ë°ì´í„° ë¡œìš° ì¸ë±ìŠ¤ ë²ˆí˜¸ ë°˜í™˜. \n",
    "n_iter =0\n",
    "for train_index, test_index  in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train= iris_df['lable'].iloc[train_index]\n",
    "    label_test= iris_df['lable'].iloc[test_index]\n",
    "    print('## êµì°¨ ê²€ì¦: {0}'.format(n_iter))\n",
    "    print('í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\\n', label_train.value_counts())\n",
    "    print('ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-19-Thu\n",
    "\n",
    "ì§„ë„: 03. Model Selection ëª¨ë“ˆ ì†Œê°œ ~ (108ìª½ ~) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë ‡ê²Œ í•˜ê²Œ ë˜ë©´ í•™ìŠµë ˆì´ë¸”ê³¼ ê²€ì¦ ë ˆì´ë¸”ì´ ì™„ì „íˆ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ì¶”ì¶œëœ ê²ƒ. ì˜ˆë¥¼ ë“¤ì–´ ì²«ë²ˆì§¸ì—ì„œëŠ” í•™ìŠµì„ 1,2ë§Œ í•˜ê³  ê²€ì¦ì€ 0ìœ¼ë¡œ í•˜ë‹ˆê¹Œ 0ì€ í•™ìŠµí•  ìˆ˜ ì—†ìŒ. ë‹¹ì—°íˆ ì´ëŸ° ìœ í˜•ìœ¼ë¡œ êµì°¨ ê²€ì¦ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„í•  í•˜ë©´ ê²€ì¦ ì˜ˆì¸¡ ì •í™•ë„ëŠ” 0ì´ ë  ìˆ˜ë°–ì— ì—†ìŒ.\n",
    "\n",
    "StratifiedKFoldëŠ” KFoldë¡œ ë¶„í• ëœ ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ê°€ ì „ì²´ ë ˆì´ë¸” ê°’ì˜ ë¶„í¬ë„ë¥¼ ë°˜ì˜í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•´ì¤Œ. ì´ ê²½ìš° í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸ ë¿ë§Œ ì•„ë‹ˆë¼ ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ë„ split() ë©”ì„œë“œì— ì¸ìë¡œ í•„ìš”í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## êµì°¨ ê²€ì¦: 1\n",
      "í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: lable, dtype: int64\n",
      "ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: lable, dtype: int64\n",
      "## êµì°¨ ê²€ì¦: 2\n",
      "í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: lable, dtype: int64\n",
      "ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: lable, dtype: int64\n",
      "## êµì°¨ ê²€ì¦: 3\n",
      "í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: lable, dtype: int64\n",
      "ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n",
      " 2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: lable, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['lable']): \n",
    "    n_iter += 1 \n",
    "    label_train = iris_df['lable'].iloc[train_index]\n",
    "    label_test = iris_df['lable'].iloc[test_index]\n",
    "    print('## êµì°¨ ê²€ì¦: {0}'.format(n_iter))\n",
    "    print('í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\\n', label_train.value_counts())\n",
    "    print('ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•™ìŠµ ë ˆì´ë¸”ê³¼ ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ê°’ì˜ ë¶„í¬ë„ê°€ ë™ì¼í•˜ê²Œ í• ë‹¹. ì´ë ‡ê²Œ ë¶„í•  ë˜ì–´ì•¼ ë ˆì´ë¸” ê°’ 0,1,2ë¥¼ ëª¨ë‘ í•™ìŠµí•  ìˆ˜ ìˆê³ , ì´ì— ê¸°ë°˜í•´ ê²€ì¦í•  ìˆ˜ ìˆìŒ. \n",
    "\n",
    "StratifiedKFoldë¥¼ ì´ìš©í•´ ë¶“ê½ƒ ë°ì´í„° êµì°¨ ê²€ì¦í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.9804, í•™ìŠµ ë°ì´í„° í¬ê¸°: 99, ê²€ì¦ ë°ì´í„° í¬ê¸°: 51\n",
      "#1 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116]\n",
      "\n",
      "#2 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.9216, í•™ìŠµ ë°ì´í„° í¬ê¸°: 99, ê²€ì¦ ë°ì´í„° í¬ê¸°: 51\n",
      "#2 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133]\n",
      "\n",
      "#3 êµì°¨ ê²€ì¦ ì •í™•ë„ :0.9792, í•™ìŠµ ë°ì´í„° í¬ê¸°: 102, ê²€ì¦ ë°ì´í„° í¬ê¸°: 48\n",
      "#3 ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## êµì°¨ ê²€ì¦ë³„ ì •í™•ë„: [0.9804 0.9216 0.9792]\n",
      "## í‰ê·  ê²€ì¦ ì •í™•ë„: 0.9604\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "# StratifiedKFoldì˜ split() í˜¸ì¶œì‹œ ë°˜ë“œì‹œ ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ë„ ì¶”ê°€ ì…ë ¥ í•„ìš”\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    # split()ìœ¼ë¡œ ë°˜í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•´ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ \n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # í•™ìŠµ ë° ì˜ˆì¸¡ \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # ë°˜ë³µ ì‹œë§ˆë‹¤ ì •í™•ë„ ì¸¡ì • \n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)  # 4ìë¦¬ ìˆ˜ì—ì„œ ë°˜ì˜¬ë¦¼\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ :{1}, í•™ìŠµ ë°ì´í„° í¬ê¸°: {2}, ê²€ì¦ ë°ì´í„° í¬ê¸°: {3}'\n",
    "         .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# êµì°¨ ê²€ì¦ë³„ ì •í™•ë„ ë° í‰ê·  ì •í™•ë„ ê³„ì‚° \n",
    "print('\\n## êµì°¨ ê²€ì¦ë³„ ì •í™•ë„:', np.round(cv_accuracy, 4))\n",
    "print('## í‰ê·  ê²€ì¦ ì •í™•ë„:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¼ë°˜ì ìœ¼ë¡œ ë¶„ë¥˜(Classification)ì—ì„œì˜ êµì°¨ ê²€ì¦ì€ K í´ë“œê°€ ì•„ë‹ˆë¼ Stratified K í´ë“œë¡œ ë¶„í• ë¼ì•¼ í•¨. íšŒê·€(Regression)ì—ì„œëŠ” Stratified K í´ë“œê°€ ì§€ì›ë˜ì§€ ì•ŠìŒ.(ì—°ì†ëœ ìˆ«ìê°’ì´ë¼ ê²°ì •ê°’ ë³„ë¡œ ë¶„í¬ë¥¼ ì •í•˜ëŠ” ì˜ë¯¸ê°€ ì—†ìŒ) \n",
    "\n",
    "##### êµì°¨ ê²€ì¦ì„ ë³´ë‹¤ ê°„í¸í•˜ê²Œ - cross_val_score()\n",
    "\n",
    "ì‚¬ì´í‚·ëŸ°ì€ êµì°¨ ê²€ì¦ì„ ì¢€ ë” í¸ë¦¬í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” API ì œê³µ. ëŒ€í‘œì ì¸ ê²ƒì´ **cross_val_score()**\n",
    "\n",
    "- cross_val_score(**estimator, X, y=None, scoring=None, cv=None**, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
    "- estimator: ë¶„ë¥˜ëƒ íšŒê·€ëƒ \n",
    "- X: í”¼ì²˜ ë°ì´í„° ì„¸íŠ¸ \n",
    "- y: ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ \n",
    "- scoring: ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ê¸°ìˆ  \n",
    "- cv: êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜ \n",
    "- ë°˜í™˜ ê°’ì€ scoring íŒŒë¼ë¯¸í„°ë¡œ ì§€ì •ëœ ì„±ëŠ¥ì§€í‘œ ì¸¡ì •ê°’ì„ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜ \n",
    "- classifierê°€ ì…ë ¥ë˜ë©´, Stratified K í´ë“œ ë°©ì‹ìœ¼ë¡œ ë ˆì´ë¸”ê°’ì˜ ë¶„í¬ì— ë”°ë¼ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ë¶„í• \n",
    "- Regressionì´ë©´, Stratified K í´ë“œ ë°©ì‹ìœ¼ë¡œ ë¶„í• í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ K í´ë“œ ë°©ì‹ìœ¼ë¡œ ë¶„í• \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "êµì°¨ ê²€ì¦ë³„ ì •í™•ë„: [0.9804 0.9216 0.9792]\n",
      "í‰ê·  ê²€ì¦ ì •í™•ë„: 0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# ì„±ëŠ¥ ì§€í‘œëŠ” ì •í™•ë„(accuracy), êµì°¨ ê²€ì¦ ì„¸íŠ¸ëŠ” 3ê°œ \n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('êµì°¨ ê²€ì¦ë³„ ì •í™•ë„:', np.round(scores, 4))\n",
    "print('í‰ê·  ê²€ì¦ ì •í™•ë„:', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score() APIëŠ” ë‚´ë¶€ì—ì„œ Estimatorë¥¼ í•™ìŠµ(fit), ì˜ˆì¸¡(predict), í‰ê°€(evaluation)ì‹œì¼œì£¼ë¯€ë¡œ ê°„ë‹¨í•˜ê²Œ êµì°¨ê²€ì¦ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ. \n",
    "\n",
    "- cross_validate(): ì—¬ëŸ¬ê°œì˜ í‰ê°€ì§€í‘œë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŒ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-20-Fri\n",
    "\n",
    "ì§„ë„: 04. Model Selection ëª¨ë“ˆ ì†Œê°œ ~ (113ìª½ ~) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV - êµì°¨ ê²€ì¦ê³¼ ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•œ ë²ˆì—\n",
    "\n",
    "í•˜ì´í¼ íŒŒë¼ë¯¸í„°ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬ì„±í•˜ëŠ” ì£¼ìš” êµ¬ì„± ìš”ì†Œì´ë©°, ì´ ê°’ì„ ì¡°ì •í•´ ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŒ. ì‚¬ì´í‚·ëŸ°ì€ GridSearchCV APIë¥¼ ì´ìš©í•´ Classifierë‚˜ Regressorì™€ ê°™ì€ ê°™ì€ ì•Œê³ ë¦¬ì¦˜ì— ì‚¬ìš©ë˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥í•˜ë©´ì„œ í¸ë¦¬í•˜ê²Œ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ì œê³µí•¨. GridSearchCVëŠ” êµì°¨ ê²€ì¦ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì˜ ìµœì  ê°’ì„ ì°¾ê²Œ í•´ì¤Œ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê³  í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ \n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                   test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# íŒŒë¼ë¯¸í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì§€ì • \n",
    "parameters = {'max_depth': [1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# param_gridì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ 3ê°œì˜ train, test set foldë¡œ ë‚˜ëˆ„ì–´ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ì„¤ì •.\n",
    "### refit=Trueê°€ defaultì„. Trueì´ë©´ ê°€ì¥ ì¢‹ì€ íŒŒë¼ë¯¸í„° ì„¤ì •ìœ¼ë¡œ ì¬í•™ìŠµì‹œí‚´. \n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# ë¶“ê½ƒ í•™ìŠµ ë°ì´í„°ë¡œ param_gridì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµ/í‰ê°€\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV ê²°ê³¼ë¥¼ ì¶”ì¶œí•´ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "### cv_results_ëŠ” gridsearchcvì˜ ê²°ê³¼ ì„¸íŠ¸\n",
    "score_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "score_df[['params','mean_test_score','rank_test_score',\n",
    "         'split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rank_test_score: í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë³„ë¡œ ì„±ëŠ¥ì´ ì¢‹ì€ score ìˆœìœ„\n",
    "- mean_test_score: ê°œë³„ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë³„ë¡œ CVì˜ í´ë”© í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•´ ì´ ìˆ˜í–‰í•œ í‰ê°€ í‰ê· ê°’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV ìµœì  íŒŒë¼ë¯¸í„°: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV ìµœê³  ì •í™•ë„:0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV ìµœì  íŒŒë¼ë¯¸í„°:', grid_dtree.best_params_)\n",
    "print('GridSearchCV ìµœê³  ì •í™•ë„:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ ì •í™•ë„: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCVì˜ refitìœ¼ë¡œ ì´ë¯¸ í•™ìŠµëœ estimator ë°˜í™˜\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCVì˜ best_estimator_ëŠ” ì´ë¯¸ ìµœì  í•™ìŠµì´ ëìœ¼ë¯€ë¡œ ë³„ë„ í•™ìŠµì´ í•„ìš” ì—†ìŒ\n",
    "pred = estimator.predict(X_test)\n",
    "print('í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ ì •í™•ë„: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-21-Sat\n",
    "\n",
    "ì§„ë„: 05. ë°ì´í„° ì „ì²˜ë¦¬ ~ (118ìª½ ~) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. ë°ì´í„° ì „ì²˜ë¦¬ \n",
    "\n",
    "ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ML ì•Œê³ ë¦¬ì¦˜ë§Œí¼ ì¤‘ìš”í•¨. ë°ì´í„°ì— ê¸°ë°˜í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ì–´ë–¤ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ê°€ì§€ëŠëƒì— ë”°ë¼ ê²°ê³¼ë„ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ. \n",
    "\n",
    "- ê²°ì†ê°’ì€ í—ˆìš©ë˜ì§€ ì•ŠìŒ! Nullê°’ì€ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨. \n",
    "    1. Null ê°’ì´ ëª‡ ì•ˆë˜ë©´, í”¼ì²˜ì˜ í‰ê· ê°’ìœ¼ë¡œ ê°„ë‹¨íˆ ëŒ€ì²´ \n",
    "    2. Null ê°’ì´ ëŒ€ë¶€ë¶„ì´ë©´, í•´ë‹¹ í”¼ì²˜ëŠ” ë“œë¡­ \n",
    "    3. Null ê°’ì´ ì¼ì • ìˆ˜ì¤€ì´ ì´ìƒì´ë©´, (ì¤‘ìš”ë„ê°€ ë†’ì€ í”¼ì²˜ë¼ë©´) Nullì„ ë‹¨ìˆœíˆ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê²Œ ë  ê²½ìš° ì˜ˆì¸¡ ì™œê³¡ì´ ì‹¬í•  ìˆ˜ ìˆìŒ. ê·¸ë˜ì„œ ì •ë°€í•œ ëŒ€ì²´ ê°’ì„ ì„ íƒí•´ì¤˜ì•¼ í•¨. \n",
    "    \n",
    "- ë¬¸ìì—´ ê°’ì„ ì…ë ¥ ê°’ìœ¼ë¡œ í—ˆìš©í•˜ì§€ ì•ŠìŒ. ğŸ‘‰ ëª¨ë“  ë¬¸ìì—´ ê°’ì€ ì¸ì½”ë”©ë¼ì„œ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨ \n",
    "    1. ë¬¸ìì—´ í”¼ì²˜ 1) ì¹´í…Œê³ ë¦¬í˜• í”¼ì²˜ 2) í…ìŠ¤íŠ¸í˜• í”¼ì²˜ \n",
    "    2. ì¹´í…Œê³ ë¦¬í˜• í”¼ì²˜ëŠ” ì½”ë“œ ê°’ìœ¼ë¡œ í‘œí˜„ \n",
    "    3. í…ìŠ¤íŠ¸í˜• í”¼ì²˜ëŠ” í”¼ì²˜ ë²¡íŠ¸í™” ë“±ì˜ ê¸°ë²•ìœ¼ë¡œ ë²¡í„°í™”í•˜ê±°ë‚˜, ë¶ˆí•„ìš”í•œ í”¼ì²˜ë¼ íŒë‹¨ë˜ë©´ ì‚­ì œ. ì£¼ë¯¼ë²ˆí˜¸ë‚˜ ë‹¨ìˆœ ë¬¸ìì—´ ì•„ì´ë””ì˜ ê²½ìš°, ì¸ì½”ë”©í•˜ì§€ ì•Šê³  ì‚­ì œí•˜ëŠ”ê²Œ ì¢‹ìŒ(ì˜ˆì¸¡ì— ì¤‘ìš”í•œ ìš”ì†Œë„ ì•„ë‹ˆê³ , ì•Œê³ ë¦¬ì¦˜ì„ ë³µì¡í•˜ê²Œ ë§Œë“¤ì–´ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦¬ê¸° ë•Œë¬¸)\n",
    "    \n",
    "#### ë°ì´í„° ì¸ì½”ë”© \n",
    "\n",
    "ëŒ€í‘œì ìœ¼ë¡œ **ë ˆì´ë¸” ì¸ì½”ë”©(Label encoding)ê³¼ ì›-í•« ì¸ì½”ë”©(One Hot encoding)**ì´ ìˆìŒ. \n",
    "\n",
    "##### ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "- ì¹´í…Œê³ ë¦¬ í”¼ì²˜ë¥¼ ì½”ë“œí˜• ìˆ«ì ê°’ìœ¼ë¡œ ë³€í™˜ \n",
    "- LabelEncoder í´ë˜ìŠ¤ë¡œ êµ¬í˜„\n",
    "- fit(), transform()ì„ í˜¸ì¶œí•´ ë ˆì´ë¸” ì¸ì½”ë”© ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ì½”ë”© ë³€í™˜ê°’: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "items = ['TV', 'ëƒ‰ì¥ê³ ','ì „ìë ˆì¸ì§€','ì»´í“¨í„°','ì„ í’ê¸°','ì„ í’ê¸°','ë¯¹ì„œ','ë¯¹ì„œ']\n",
    "\n",
    "# LabelEncoderë¥¼ ê°ì²´ë¡œ ìƒì„±í•œ í›„, fit()ê³¼ transform()ìœ¼ë¡œ ë ˆì´ë¸” ì¸ì½”ë”© ìˆ˜í–‰. \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('ì¸ì½”ë”© ë³€í™˜ê°’:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ì½”ë”© í´ë˜ìŠ¤: ['TV' 'ëƒ‰ì¥ê³ ' 'ë¯¹ì„œ' 'ì„ í’ê¸°' 'ì „ìë ˆì¸ì§€' 'ì»´í“¨í„°']\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ê°€ ë§ì€ ê²½ìš° classes_ ì†ì„±ê°’ìœ¼ë¡œ í™•ì¸\n",
    "### ìˆœì„œëŒ€ë¡œ 0,1,2,3,4,5ë¡œ ì¸ì½”ë”©\n",
    "print('ì¸ì½”ë”© í´ë˜ìŠ¤:', encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ì½”ë”© ì›ë³¸ê°’: ['ì „ìë ˆì¸ì§€' 'ì»´í“¨í„°' 'ë¯¹ì„œ' 'TV' 'ëƒ‰ì¥ê³ ' 'ëƒ‰ì¥ê³ ' 'ì„ í’ê¸°' 'ì„ í’ê¸°']\n"
     ]
    }
   ],
   "source": [
    "# inverse_transform()ìœ¼ë¡œ ë‹¤ì‹œ ë””ì½”ë”© \n",
    "print('ë””ì½”ë”© ì›ë³¸ê°’:', encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¬ë‚˜ ëª‡ëª‡ ML ì•Œê³ ë¦¬ì¦˜ì—ëŠ” ì´ë¥¼ ì ìš©í•  ë•Œ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ê²½ìš°ê°€ ë°œìƒ. **ìˆ«ì ê°’ì˜ ê²½ìš° í¬ê³  ì‘ìŒì— ëŒ€í•œ íŠ¹ì„±ì´ ì‘ìš©**í•˜ê¸° ë•Œë¬¸. íŠ¹ì • ML ì•Œê³ ë¦¬ì¦˜ì—ì„œ ê°€ì¤‘ì¹˜ê°€ ë” ë¶€ì—¬ë˜ê±°ë‚˜ ë” ì¤‘ìš”í•˜ê²Œ ì¸ì‹í•  ê°€ëŠ¥ì„±ì´ ë°œìƒ. ê·¸ë˜ì„œ ë ˆì´ë¸” ì¸ì½”ë”©ì€ ì„ í˜• íšŒê·€ì™€ ê°™ì€ ML ì•Œê³ ë¦¬ì¦˜ì— ì ìš©í•˜ì§€ ì•Šì•„ì•¼ í•¨. \n",
    "\n",
    "ì´ëŸ° ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ê²ƒì´ **ì›-í•« ì¸ì½”ë”©** ë°©ì‹\n",
    "\n",
    "##### ì›-í•« ì¸ì½”ë”©(One-Hot Encoding)\n",
    "\n",
    "í”¼ì²˜ ê°’ì˜ ìœ í˜•ì— ë”°ë¼ ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ì¶”ê°€í•´ ê³ ìœ  ê°’ì— í•´ë‹¹í•˜ëŠ” ì¹¼ëŸ¼ì—ë§Œ 1ì„ í‘œì‹œí•˜ê³  ë‚˜ë¨¸ì§€ ì¹¼ëŸ¼ì—ëŠ” 0ì„ í‘œì‹œí•˜ëŠ” ë°©ì‹.\n",
    "- OneHotEncoder í´ë˜ìŠ¤ë¡œ ì‰½ê²Œ ë³€í™˜\n",
    "    1. OneHotEncoderë¡œ ë³€í™˜í•˜ê¸° ì „ì— ëª¨ë“  ë¬¸ìì—´ ê°’ì´ ìˆ«ìí˜• ê°’ìœ¼ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•¨\n",
    "    2. ì…ë ¥ ê°’ìœ¼ë¡œ 2ì°¨ì› ë°ì´í„°ê°€ í•„ìš”í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import numpy as np \n",
    "\n",
    "items = ['TV','ëƒ‰ì¥ê³ ','ì „ìë ˆì¸ì§€','ì»´í“¨í„°','ì„ í’ê¸°','ì„ í’ê¸°','ë¯¹ì„œ','ë¯¹ì„œ']\n",
    "\n",
    "# ë¨¼ì € ìˆ«ì ê°’ìœ¼ë¡œ ë³€í™˜ì„ ìœ„í•´ LabelEncoderë¡œ ë³€í™˜í•¨ \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# 2ì°¨ì› ë°ì´í„°ë¡œ ë³€í™˜\n",
    "labels = labels.reshape(-1,1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›-í•« ì¸ì½”ë”© ë°ì´í„°\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "ì›-í•« ì¸ì½”ë”© ë°ì´í„° ì°¨ì›\n",
      "(8, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harampark/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ì›-í•« ì¸ì½”ë”© ì ìš©\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('ì›-í•« ì¸ì½”ë”© ë°ì´í„°')\n",
    "print(oh_labels.toarray())\n",
    "print('ì›-í•« ì¸ì½”ë”© ë°ì´í„° ì°¨ì›')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- íŒë‹¤ìŠ¤ëŠ” ì›-í•« ì¸ì½”ë”©ì„ ë” ì‰½ê²Œ ì§€ì›í•˜ëŠ” **get_dummies()** APIê°€ ìˆìŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items_TV</th>\n",
       "      <th>items_ëƒ‰ì¥ê³ </th>\n",
       "      <th>items_ë¯¹ì„œ</th>\n",
       "      <th>items_ì„ í’ê¸°</th>\n",
       "      <th>items_ì „ìë ˆì¸ì§€</th>\n",
       "      <th>items_ì»´í“¨í„°</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   items_TV  items_ëƒ‰ì¥ê³   items_ë¯¹ì„œ  items_ì„ í’ê¸°  items_ì „ìë ˆì¸ì§€  items_ì»´í“¨í„°\n",
       "0         1          0         0          0            0          0\n",
       "1         0          1         0          0            0          0\n",
       "2         0          0         0          0            1          0\n",
       "3         0          0         0          0            0          1\n",
       "4         0          0         0          1            0          0\n",
       "5         0          0         0          1            0          0\n",
       "6         0          0         1          0            0          0\n",
       "7         0          0         1          0            0          0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame({'items':['TV','ëƒ‰ì¥ê³ ','ì „ìë ˆì¸ì§€','ì»´í“¨í„°','ì„ í’ê¸°','ì„ í’ê¸°','ë¯¹ì„œ','ë¯¹ì„œ']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-03-22-Sun\n",
    "\n",
    "ì§„ë„: 05. ë°ì´í„° ì „ì²˜ë¦¬ ~ (124ìª½ ~) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ê³¼ ì •ê·œí™” \n",
    "\n",
    "í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ì€ ì„œë¡œ ë‹¤ë¥¸ ë³€ìˆ˜ì˜ ê°’ ë²”ìœ„ë¥¼ ì¼ì •í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë§ì¶”ëŠ” ì‘ì—…. \n",
    "\n",
    "- í‘œì¤€í™”: ë°ì´í„° í”¼ì²˜ ê°ê°ì´ í‰ê· =0, ë¶„ì‚°=1ì¸ ì •ê·œë¶„í¬ë¥¼ ê°€ì§„ ê°’ìœ¼ë¡œ ë³€í™˜ \n",
    "- ì •ê·œí™”: ì„œë¡œ ë‹¤ë¥¸ í”¼ì²˜ì˜ í¬ê¸°ë¥¼ í†µì¼í•˜ê¸°ìœ„í•´ í¬ê¸°ë¥¼ ë³€í™˜í•´ì£¼ëŠ” ê°œë…, ìµœì†Œ 0 ~ ìµœëŒ€1ì˜ ê°’ìœ¼ë¡œ ë³€í™˜. ê°œë³„ ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ëª¨ë‘ ë˜‘ê°™ì€ ë‹¨ìœ„ë¡œ ë³€ê²½. \n",
    "- ë²¡í„° ì •ê·œí™”: ì„ í˜•ëŒ€ìˆ˜ì—ì„œì˜ ì •ê·œí™” ê°œë… ì ìš©, ê°œë³„ ë²¡í„°ì˜ í¬ê¸°ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ë³€í™˜í•˜ëŠ” ê²ƒì„ ì˜ë¯¸. ì¦‰, ê°œë³„ ë²¡í„°ë¥¼ ëª¨ë“  í”¼ì²˜ ë²¡í„°ì˜ í¬ê¸°ë¡œ ë‚˜ëˆ ì¤Œ. -> í¬ê¸°ê°€ 1ì¸ ë²¡í„°ë¡œ í‘œì¤€í™” ì‹œì¼œì£¼ëŠ” ê²ƒ(ë‹¨ìœ„ ë²¡í„°) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandardScaler \n",
    "\n",
    "í‘œì¤€í™”ë¥¼ ì‰½ê²Œ ì§€ì›í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "import pandas as pd \n",
    "\n",
    "# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë”©í•˜ê³  DataFrameìœ¼ë¡œ ë³€í™˜ \n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(iris_data, columns = iris.feature_names)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureë“¤ì˜ í‰ê·  ê°’\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "featureë“¤ì˜ ë¶„ì‚° ê°’\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('featureë“¤ì˜ í‰ê·  ê°’')\n",
    "print(iris_df.mean())\n",
    "print('featureë“¤ì˜ ë¶„ì‚° ê°’')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "feature ë“¤ì˜ í‰ê·  ê°’\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature ë“¤ì˜ ë¶„ì‚° ê°’\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScalerê°ì²´ ìƒì„± \n",
    "scaler = StandardScaler()\n",
    "# StandardScalerë¡œ ë°ì´í„° ì„¸íŠ¸ ë³€í™˜. fit()ê³¼ transform() í˜¸ì¶œ. \n",
    "scaler.fit(iris_df)\n",
    "iris_scared = scaler.transform(iris_df)\n",
    "print(type(iris_scared))\n",
    "\n",
    "# transform()ì‹œ ìŠ¤ì¼€ì¼ ë³€í™˜ëœ ë°ì´í„° ì„¸íŠ¸ê°€ NumPy ndarrayë¡œ ë°˜í™˜ë¼ ì´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ \n",
    "iris_df_scaled = pd.DataFrame(data=iris_scared, columns=iris.feature_names)\n",
    "print('feature ë“¤ì˜ í‰ê·  ê°’')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature ë“¤ì˜ ë¶„ì‚° ê°’')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler \n",
    "\n",
    "ë°ì´í„°ê°’ì„ 0ê³¼ 1ì‚¬ì´ì˜ ë²”ìœ„ ê°’ìœ¼ë¡œ ë³€í™˜. (-1 ìŒìˆ˜ê°€ ìˆìœ¼ë©´ 1ê°’ìœ¼ë¡œ ë³€í™˜) ë°ì´í„°ì˜ ë¶„í¬ê°€ ê°€ìš°ì‹œì•ˆ ë¶„í¬ê°€ ì•„ë‹ ê²½ìš°ì— Min, Max Scalerì„ ì ìš©í•´ ë³¼ ìˆ˜ ìˆìŒ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature ë“¤ì˜ í‰ê·  ê°’\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature ë“¤ì˜ ë¶„ì‚° ê°’\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "# MinMaxScaler ìƒì„± \n",
    "scaler = MinMaxScaler()\n",
    "# MinMaxScalerë¡œ ë°ì´í„° ì„¸íŠ¸ ë³€í™˜. fit()ê³¼ transform() í˜¸ì¶œ.\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform()ì‹œ ìŠ¤ì¼€ì¼ ë³€í™˜ëœ ë°ì´í„° ì„¸íŠ¸ê°€ NumPy ndarrayë¡œ ë°˜í™˜ë¼ ì´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ \n",
    "iris_df_scaled = pd.DataFrame(iris_scaled, columns=iris.feature_names)\n",
    "print('feature ë“¤ì˜ í‰ê·  ê°’')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature ë“¤ì˜ ë¶„ì‚° ê°’')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ ë³€í™˜ ì‹œ ìœ ì˜ì \n",
    "\n",
    "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¡œëŠ” ë‹¤ì‹œ fit()ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë¡œ fit()ì„ ìˆ˜í–‰í•œ ê²°ê³¼ë¥¼ ì´ìš©í•´ transform() ë³€í™˜ì„ ì ìš©í•´ì•¼ í•¨. ìƒˆë¡œ í•˜ê²Œ ë˜ë©´, í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ ê¸°ì¤€ ì •ë³´ê°€ ì„œë¡œ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import numpy as np \n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ëŠ” 0ë¶€í„° 10ê¹Œì§€, í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” 0ë¶€í„° 5ê¹Œì§€ ê°’ì„ ê°€ì§€ëŠ” ë°ì´í„° ì„¸íŠ¸ë¡œ ìƒì„± \n",
    "# Scaler í´ë˜ìŠ¤ì˜ fit(), transform()ì€ 2ì°¨ì› ì´ìƒ ë°ì´í„°ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ reshape(1,1)ë¡œ ì°¨ì› ë³€ê²½\n",
    "train_array = np.arange(0,11).reshape(-1,1)\n",
    "test_array = np.arange(0,6).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ train_array ë°ì´í„°: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scaleëœ train_array ë°ì´í„°: [ 0  1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler ê°ì²´ì— ë³„ë„ì˜ feature_range íŒŒë¼ë¯¸í„° ê°’ì„ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ 0~1 ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit()í•˜ê²Œ ë˜ë©´ test_array ë°ì´í„°ì˜ ìµœì†Ÿê°’ì´ 0, ìµœëŒ“ê°’ì´ 10ìœ¼ë¡œ ì„¤ì •. \n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1/10 scaleë¡œ train_array ë°ì´í„° ë³€í™˜í•¨. ì›ë³¸ 10 -> 1ë¡œ ë³€í™˜ë¨. \n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('ì›ë³¸ train_array ë°ì´í„°:', np.round(train_array.reshape(-1),2))\n",
    "print('Scaleëœ train_array ë°ì´í„°:', np.round(train_array.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ train_array ë°ì´í„°: [0 1 2 3 4 5]\n",
      "Scaleëœ train_array ë°ì´í„°: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# fit()ì„ ìƒˆë¡œ í˜¸ì¶œí•˜ê²Œ ë˜ë©´? \n",
    "\n",
    "# MinMaxScalerì— test_arrayë¥¼ fit()í•˜ê²Œ ë˜ë©´ ì›ë³¸ ë°ì´í„°ì˜ ìµœì†Ÿê°’ì´ 0, ìµœëŒ“ê°’ì´ 5ë¡œ ì„¤ì •ë¨\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1/5 scaleë¡œ test_array ë°ì´í„° ë³€í™˜í•¨. ì›ë³¸ 5->1ë¡œ ë³€í™˜. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "# test_arrayì˜ scaler ë³€í™˜ ì¶œë ¥. \n",
    "print('ì›ë³¸ train_array ë°ì´í„°:', np.round(test_array.reshape(-1),2))\n",
    "print('Scaleëœ train_array ë°ì´í„°:', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶œë ¥ ê²°ê³¼ëŠ” í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ì´ ë§ì§€ ì•ŠìŒì„ ì•Œ ìˆ˜ ìˆìŒ. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµë˜ê¸° ë•Œë¬¸ì— ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í•™ìŠµ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ ê¸°ì¤€ì— ë”°ë¼ì•¼ í•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ 1ê°’ì€ í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•˜ê²Œ 0.1ê°’ìœ¼ë¡œ ë³€í™˜ë¼ì•¼ í•¨. ë”°ë¼ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ë‹¤ì‹œ fit()ì„ ì ìš©í•´ì„œëŠ” ì•ˆ ë˜ë©° í•™ìŠµ ë°ì´í„°ë¡œ ì´ë¯¸ fit()ì´ ì ìš©ëœ Scaler ê°ì²´ë¥¼ ì´ìš©í•´ transform()ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ train_array ë°ì´í„°: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scaleëœ train_array ë°ì´í„°: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "ì›ë³¸ train_array ë°ì´í„°: [0 1 2 3 4 5]\n",
      "Scaleëœ train_array ë°ì´í„°: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('ì›ë³¸ train_array ë°ì´í„°:', np.round(train_array.reshape(-1),2))\n",
    "print('Scaleëœ train_array ë°ì´í„°:', np.round(train_scaled.reshape(-1),2))\n",
    "\n",
    "# test_arrayì— Scale ë³€í™˜ì„ í•  ë•ŒëŠ” ë°˜ë“œì‹œ fit()ì„ í˜¸ì¶œí•˜ì§€ ì•Šê³  transform()ë§Œìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\nì›ë³¸ train_array ë°ì´í„°:', np.round(test_array.reshape(-1),2))\n",
    "print('Scaleëœ train_array ë°ì´í„°:', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_transform()ì„ ì ìš©í•  ë•Œë„ ë§ˆì°¬ê°€ì§€ì„. \n",
    "\n",
    "1. ê°€ëŠ¥í•˜ë‹¤ë©´ ì „ì²´ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ ë³€í™˜ì„ ì ìš©í•œ ë’¤ í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬ \n",
    "2. 1ì´ ì—¬ì˜ì¹˜ ì•Šë‹¤ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ ì‹œì—ëŠ” fit()ì´ë‚˜ fit_transform()ì„ ì ìš©í•˜ì§€ì•Šê³  í•™ìŠµ ë°ì´í„°ë¡œ ì´ë¯¸ fit()ëœ Scaler ê°ì²´ë¥¼ ì´ìš©í•´ transform()ìœ¼ë¡œ ë³€í™˜"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
